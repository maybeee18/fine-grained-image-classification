{"cells":[{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"l50ayMtNINEW","outputId":"e5141a6a-db1c-446a-895e-41ae893c6032","trusted":true},"cell_type":"code","source":"!ls ../input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cat /proc/meminfo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"8hk2YZ5wXey9"},"cell_type":"markdown","source":"### Importing Required Libraries"},{"metadata":{"colab":{},"colab_type":"code","id":"i_3MlXOFINOF","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom pathlib import Path\nfrom torch.utils.data import Dataset, DataLoader, random_split, sampler\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models, datasets, models\nimport random\nimport cv2\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\nimport math\nimport xml.etree.ElementTree as ET","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"-MhlChXPBYnD","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checks for the availability of GPU \nif torch.cuda.is_available():\n    print(\"working on gpu!\")\n    device = 'cuda'\nelse:\n    print(\"No gpu! only cpu ;)\")\n    device = 'cpu'\n    \n## The following random seeds are just for deterministic behaviour of the code and evaluation\n\n##############################################################################\n################### DO NOT MODIFY THE CODE BELOW #############################    \n##############################################################################\n\nif device == 'cpu':    \n    random.seed(0)\n    np.random.seed(0)\n    torch.manual_seed(0)\nelif device == 'cuda':\n    random.seed(0)\n    np.random.seed(0)\n    torch.manual_seed(0)\n    torch.cuda.manual_seed_all(0)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = '0'\n\n###############################################################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image(breed, dog, data_dir):\n    img = plt.imread(data_dir + 'images/Images/' + breed + '/' + dog + '.jpg')\n    tree = ET.parse(data_dir + 'annotations/Annotation/' + breed + '/' + dog)\n    xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n    xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n    ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n    ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n    img = img[ymin:ymax, xmin:xmax, :]\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/stanford-dogs-dataset/'\nbreed_list = os.listdir(data_dir + 'images/Images/')\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(4):\n    \n    plt.subplot(421 + (i*2))\n    \n    breed = np.random.choice(breed_list)\n    dog = np.random.choice(os.listdir(data_dir + 'annotations/Annotation/' + breed))\n    img = plt.imread(data_dir + 'images/Images/' + breed + '/' + dog + '.jpg')\n    plt.imshow(img)\n    \n    tree = ET.parse(data_dir + 'annotations/Annotation/' + breed + '/' + dog)\n    xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n    xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n    ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n    ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n    \n    plt.plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin])\n    \n    crop_img = crop_image(breed, dog, data_dir)\n    print(crop_img.shape)\n    plt.subplot(422 + (i*2))\n    plt.imshow(crop_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 'cropped_data' not in os.listdir():\n    \n    os.mkdir('cropped_data')\n    \n    for breed in breed_list:\n        os.mkdir('cropped_data/' + breed)\n    \nprint('Created {} folders to store cropped images of the different breeds.'.format(len(os.listdir('cropped_data'))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for breed in tqdm(os.listdir('cropped_data')):\n    \n    for file in os.listdir(data_dir + 'annotations/Annotation/' + breed):\n        \n        img = Image.open(data_dir + 'images/Images/' + breed + '/' + file + '.jpg')\n        tree = ET.parse(data_dir + 'annotations/Annotation/' + breed + '/' + file)\n        xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n        xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n        ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n        ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n        img = img.crop((xmin,ymin,xmax,ymax))\n        img = img.convert('RGB')\n        img.save('cropped_data/' + breed + '/' + file + '.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_count = 0\n\nfor folder in os.listdir('cropped_data'):\n    \n    for _ in os.listdir('cropped_data/' + folder):    \n        img_count += 1\n    \nprint('No. of Images: {}'.format(img_count))","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"P-sdyCuSIWoy","trusted":true},"cell_type":"code","source":"# Data Augmentation\nbatch_size = 128\nimage_size = 299\n\nimage_transforms = {\n    \n    'train':torchvision.transforms.Compose([\n            torchvision.transforms.Resize(size=image_size),\n            torchvision.transforms.RandomHorizontalFlip(),\n            torchvision.transforms.RandomCrop(size=image_size),\n            torchvision.transforms.ToTensor(),\n            torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n                                             std=(0.229, 0.224, 0.225))\n    ]),\n    'val':torchvision.transforms.Compose([\n            torchvision.transforms.Resize(size=image_size),\n            torchvision.transforms.CenterCrop(size=image_size),\n            torchvision.transforms.ToTensor(),\n            torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n                                             std=(0.229, 0.224, 0.225))\n        ])\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = datasets.ImageFolder(root='cropped_data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_len = int(len(all_data) * 0.8)\nvalid_data_len = int((len(all_data) - train_data_len) / 2)\ntest_data_len = int(len(all_data) - train_data_len - valid_data_len)\n\ntrain_data, val_data, test_data = random_split(all_data, [train_data_len, valid_data_len, test_data_len])\n\ntrain_data.dataset.transform = image_transforms['train']\nval_data.dataset.transform = image_transforms['val']\ntest_data.dataset.transform = image_transforms['val']\n\nprint(len(train_data), len(val_data), len(test_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"M0MXyc5MYrCD"},"cell_type":"markdown","source":"### Define Model BCNN\n**We will use DenseNet as the base architecture as suggested in the paper**"},{"metadata":{"colab_type":"text","id":"a0FsRQUjYz4v"},"cell_type":"markdown","source":"![title](http://vis-www.cs.umass.edu/bcnn/docs/teaser-bcnn.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainiter = iter(train_loader)\nfeatures, labels = next(trainiter)\nprint(features.shape, labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"densenet = models.densenet121(pretrained=True)\n\n# freezing parameters\nfor param in densenet.parameters():\n    param.requires_grad = False\n\nlayers = list(models.densenet121().children())[:-1]\ndensenet = nn.Sequential(*layers).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"densenet(torch.randn(1, 3, image_size, image_size).cuda()).shape","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"yLSGmyr5Iuh0","trusted":true},"cell_type":"code","source":"features = 1024\nfmap_size = 9\n\nclass BCNN(nn.Module):\n    def __init__(self, fine_tune=False):\n        super(BCNN, self).__init__()\n        \n        base_net = models.densenet121(pretrained=True)\n        \n        # freezing parameters\n        if not fine_tune:\n            for param in base_net.parameters():\n                param.requires_grad = False\n        else:\n            \n            for param in base_net.parameters():\n                param.requires_grad = True\n\n        layers = list(base_net.children())[:-1]\n        self.features = nn.Sequential(*layers).cuda()        \n\n        self.fc = nn.Linear(features ** 2, 120)\n        self.dropout = nn.Dropout(0.5)\n        \n        # Initialize the fc layers.\n        nn.init.xavier_normal_(self.fc.weight.data)\n        \n        if self.fc.bias is not None:\n            torch.nn.init.constant_(self.fc.bias.data, val=0)\n        \n     \n    def forward(self, x):\n        \n        ## X: bs, 3, 256, 256\n        ## N = bs\n        N = x.size()[0]\n        \n        ## x : bs, 1024, 14, 14\n        x = self.features(x)\n        \n        # bs, (1024 * 196) matmul (196 * 1024)\n        x = x.view(N, features, fmap_size ** 2)\n        x = F.relu(x)\n        \n        x = self.dropout(x)\n        # Batch matrix multiplication\n        x = torch.bmm(x, torch.transpose(x, 1, 2))/ (fmap_size ** 2) \n        x = x.view(N, features ** 2)\n        \n        x = torch.sqrt(x + 1e-5)\n        x = F.normalize(x)\n        x = self.dropout(x)\n        x = self.fc(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = BCNN().cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.class_to_idx = all_data.class_to_idx\nmodel.idx_to_class = {\n    idx: class_\n    for class_, idx in model.class_to_idx.items()\n}\n\nlist(model.idx_to_class.items())","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"jEmypS6AfKFs","trusted":true},"cell_type":"code","source":"def train(model, \n          criterion, \n          optimizer, \n          train_loader,\n          val_loader, \n          save_location, \n          early_stop=3, \n          n_epochs=20, \n          print_every=1):\n\n    #Initializing some variables\n    valid_loss_min = np.Inf\n    stop_count = 0\n    valid_max_acc = 0\n    history = []\n    model.epochs = 0\n\n    #Loop starts here\n    for epoch in range(n_epochs):\n        \n        train_loss = 0\n        valid_loss = 0\n\n        train_acc = 0\n        valid_acc = 0\n\n        model.train()\n        \n        ### batch control\n        ii = 0\n        \n        for data, label in train_loader:\n            \n            ii += 1\n            \n            data, label = data.cuda(), label.cuda()\n            output = model(data)\n            \n            loss = criterion(output, label)\n            optimizer.zero_grad()\n            \n            loss.backward()\n            optimizer.step()\n            \n            # Track train loss by multiplying average loss by number of examples in batch\n            train_loss += loss.item() * data.size(0)\n            \n            \n            # Calculate accuracy by finding max log probability\n            # first output gives the max value in the row(not what we want), second output gives index of the highest val\n            _, pred = torch.max(output, dim=1)\n            \n            # using the index of the predicted outcome above, torch.eq() will check prediction index against label index to see if prediction is correct(returns 1 if correct, 0 if not)\n            correct_tensor = pred.eq(label.data.view_as(pred))\n            \n            #tensor must be float to calc average\n            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n            train_acc += accuracy.item() * data.size(0)\n            \n            if ii%10 == 0:\n                print(f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete.')\n        \n        model.epochs += 1\n        \n        with torch.no_grad():\n            \n            model.eval()\n            \n            for data, label in val_loader:\n                \n                data, label = data.cuda(), label.cuda()\n                output = model(data)\n                loss = criterion(output, label)\n                valid_loss += loss.item() * data.size(0)\n                \n                _, pred = torch.max(output, dim=1)\n                correct_tensor = pred.eq(label.data.view_as(pred))\n                accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n                valid_acc += accuracy.item() * data.size(0)\n            \n            train_loss = train_loss / len(train_loader.dataset)\n            valid_loss = valid_loss / len(val_loader.dataset)\n\n            train_acc = train_acc / len(train_loader.dataset)\n            valid_acc = valid_acc / len(val_loader.dataset)\n\n            history.append([train_loss, valid_loss, train_acc, valid_acc])\n\n            if (epoch + 1) % print_every == 0:\n                \n                print(f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}')\n                print(f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%')\n\n            if valid_loss < valid_loss_min:\n                \n                torch.save({\n                    'state_dict': model.state_dict()\n                    #'idx_to_class': model.idx_to_class\n                }, save_location)\n                \n                stop_count = 0\n                valid_loss_min = valid_loss\n                valid_best_acc = valid_acc\n                best_epoch = epoch\n\n            else:\n                \n                stop_count += 1\n                \n                # Below is the case where we handle the early stop case\n                if stop_count >= early_stop:\n                    \n                    print(f'\\nEarly Stopping Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n                    model.load_state_dict(torch.load(save_location)['state_dict'])\n                    model.optimizer = optimizer\n                    history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc','valid_acc'])\n                    return model, history\n    \n    model.optimizer = optimizer\n    print(f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n\n    history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n    \n    return model, history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model, history = train(\n    model,\n    criterion,\n    optimizer,\n    train_loader,\n    val_loader,\n    save_location='dog_bcnn.pt',\n    early_stop=3,\n    n_epochs=50,\n    print_every=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(model, test_loader, criterion):\n    with torch.no_grad():\n        model.eval()\n        test_acc = 0\n        \n        for data, label in test_loader:\n            data, label = data.cuda(), label.cuda()\n\n            output = model(data)\n\n            _, pred = torch.max(output, dim=1)\n            correct_tensor = pred.eq(label.data.view_as(pred))\n            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n            test_acc += accuracy.item() * data.size(0)\n\n        test_acc = test_acc / len(test_loader.dataset)\n        return test_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load('dog_bcnn.pt')['state_dict'])\ntest_acc = test(model.cuda(), test_loader, criterion)\nprint(f'The model has achieved an accuracy of {100 * test_acc:.2f}% on the test dataset')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchsummary import summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(model, input_size=(3, image_size, image_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = BCNN(fine_tune=True).cuda()\nmodel.load_state_dict(torch.load('dog_bcnn.pt')['state_dict'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"batch_size = 64\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n\noptimizer = optim.Adam(model.parameters(), lr=0.00001)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"summary(model, input_size=(3, image_size, image_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model, history = train(\n    model,\n    criterion,\n    optimizer,\n    train_loader,\n    val_loader,\n    save_location='dog_bcnn_finetuned.pt',\n    early_stop=3,\n    n_epochs=50,\n    print_every=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"BCNN_for_CUS-200.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"bcnn","language":"python","name":"bcnn"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":1}